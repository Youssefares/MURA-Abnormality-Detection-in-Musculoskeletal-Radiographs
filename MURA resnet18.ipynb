{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from fastai.vision import transform\n",
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    " \n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\t\t       train_labeled_studies.csv  valid_image_paths.csv\r\n",
      "train_image_paths.csv  valid\t\t\t  valid_labeled_studies.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls MURA-v1.1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MURA-v1.1/valid/XR_WRIST/patient11185/study1_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MURA-v1.1/valid/XR_WRIST/patient11185/study1_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MURA-v1.1/valid/XR_WRIST/patient11185/study1_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MURA-v1.1/valid/XR_WRIST/patient11185/study1_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MURA-v1.1/valid/XR_WRIST/patient11186/study1_p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  MURA-v1.1/valid/XR_WRIST/patient11185/study1_p...\n",
       "1  MURA-v1.1/valid/XR_WRIST/patient11185/study1_p...\n",
       "2  MURA-v1.1/valid/XR_WRIST/patient11185/study1_p...\n",
       "3  MURA-v1.1/valid/XR_WRIST/patient11185/study1_p...\n",
       "4  MURA-v1.1/valid/XR_WRIST/patient11186/study1_p..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labled_studies = pd.read_csv('MURA-v1.1/valid_image_paths.csv', header=None)\n",
    "train_labled_studies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/image1.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labled_studies.loc[0].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_labled_studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuraDatasetByStudy(Dataset):\n",
    "    def __init__(self, csv_file, transform):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            transform (callable): Transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_csv(csv_file, header=None)\n",
    "        self.study_pths = df.iloc[:,0]\n",
    "        self.labels = df.iloc[:, 1]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.study_pths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        study_path = self.study_pths[idx]\n",
    "        \n",
    "        # get images for this study\n",
    "        i = 0\n",
    "        images = []\n",
    "        while(True):\n",
    "            img_name = study_path + 'image%s.png' % (i+1)\n",
    "            try:\n",
    "                img = Image.open(img_name)\n",
    "                img = img.convert('RGB')\n",
    "                images.append(self.transform(img))\n",
    "                i += 1\n",
    "            except FileNotFoundError:\n",
    "                break\n",
    "        \n",
    "        images = torch.stack(images)\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        m = re.match(r'.*/XR_(\\w*)/patient(\\d+)/study(\\d+)_', img_name)\n",
    "        study_type = m.group(1)\n",
    "        study_id = m.group(2)+'/'+m.group(3)\n",
    "        \n",
    "        return images, study_type, study_id, label\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.idx = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.idx >= len(self):\n",
    "            raise StopIteration\n",
    "        \n",
    "        result = self[self.idx]\n",
    "        self.idx += 1\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuraDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform, augment_transforms=[]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        traindf = pd.read_csv(csv_file, header=None)\n",
    "        self.train_img_pths = traindf.iloc[:,0]\n",
    "        self.transform = transform\n",
    "        self.augment_transforms = augment_transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.augment_transforms)+1)*len(self.train_img_pths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.train_img_pths):\n",
    "            idx = idx%len(self.train_img_pths)\n",
    "            transform = self.augment_transforms[idx//len(self.train_img_pths)-0]\n",
    "        else:\n",
    "            transform = self.transform\n",
    "\n",
    "        img_name = self.train_img_pths[idx]\n",
    "        img = Image.open(img_name)\n",
    "        img = img.convert('RGB')\n",
    "        img = transform(img)\n",
    "        \n",
    "        img_study_type = re.match(r'.*/XR_(\\w*)/', img_name).group(1)\n",
    "        img_label = int(\n",
    "            re.match(r'.*/study\\d+_(\\w+)/', img_name).group(1) == 'positive'\n",
    "        )\n",
    "        img_study_name = re.match(r'(.*/).*png', img_name).group(1)\n",
    "        \n",
    "        return img, img_study_name, img_study_type, img_label\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.idx = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.idx >= len(self):\n",
    "            raise StopIteration\n",
    "        \n",
    "        result = self[self.idx]\n",
    "        self.idx += 1\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = models.resnet18(pretrained=False)\n",
    "# freeze everything to extract feature vector\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# replace linear layer\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (224, 224)\n",
    "data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "                transforms.RandomAffine(\n",
    "                    degrees=30,\n",
    "                    translate=(0, 0.2),\n",
    "                    scale=(1, 1.5),\n",
    "                    shear=10,\n",
    "                ),\n",
    "                transforms.Resize(input_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]),\n",
    "        'valid': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "\n",
    "datasets_dict = {\n",
    "    x: MuraDataset(\n",
    "        csv_file='MURA-v1.1/%s_image_paths.csv' % x,\n",
    "        transform=data_transforms[x],\n",
    "        augment_transforms=[],\n",
    "    ) for x in ['train', 'valid']\n",
    "}\n",
    "\n",
    "# # subset\n",
    "# dataloaders_dict = {\n",
    "#     x: DataLoader(\n",
    "#         torch.utils.data.Subset(\n",
    "#             dataset=datasets_dict[x],\n",
    "#             indices=np.random.randint(\n",
    "#                 len(datasets_dict[x]),\n",
    "#                 size=100,\n",
    "#             ),\n",
    "#         ),\n",
    "#         batch_size=batch_size,\n",
    "#         num_workers=8,\n",
    "#     ) for x in ['train', 'valid']\n",
    "# }\n",
    "\n",
    "dataloaders_dict = {\n",
    "    x: DataLoader(\n",
    "        datasets_dict[x],\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=8,\n",
    "    ) for x in ['train', 'valid']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_learning_rate(optimizer, update):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = update(param_group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_n = 7\n",
    "M = 5\n",
    "T = len(dataloaders_dict['train'].dataset)/batch_size*epoch_n*M\n",
    "\n",
    "def shifted_cosine_function(t, lr):\n",
    "    return lr/2*(np.cos(np.pi*((t-1)%np.ceil(T/M))/np.ceil(T/M))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, epoch_n, validation_loader):\n",
    "    model = model.to(device)\n",
    "    last_valid_acc = 0\n",
    "    \n",
    "    for epoch in range(epoch_n):\n",
    "        model.train()\n",
    "        print('=========================epoch %i=====================' % epoch)\n",
    "        epoch_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "        epoch_corrects = 0\n",
    "        for i, data in enumerate(tqdm(train_loader)):\n",
    "            inputs, _, study_type, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.sum().backward()\n",
    "            optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.sum()\n",
    "            epoch_loss += loss.sum()\n",
    "\n",
    "        epoch_loss = epoch_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = epoch_corrects.double() / len(train_loader.dataset)\n",
    "        print('epoch loss: %.8f' % epoch_loss)\n",
    "        print('epoch accuracy: %.8f' % epoch_accuracy)\n",
    "\n",
    "        # else evaluate first then keep training\n",
    "        _, valid_loss, valid_acc, valid_kappa = validate_model(\n",
    "            [model],\n",
    "            validation_loader,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "        )\n",
    "        \n",
    "        print('epoch valid_loss: %8f' % valid_loss)\n",
    "        print('epoch valid_acc: %.8f' % valid_acc)\n",
    "        print('last epoch valid_acc: %.8f' % last_valid_acc)\n",
    "        print('epoch valid_kappa: %.8f' % valid_kappa)\n",
    "\n",
    "        if abs(valid_acc - last_valid_acc) < 0.0001:\n",
    "            update_learning_rate(optimizer, update= lambda x: 0.1*x)\n",
    "        last_valid_acc = valid_acc\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_snapshot_ensembling(model, train_loader, criterion, optimizer, epoch_n, cycles, validation_loader):\n",
    "    model = model.to(device)\n",
    "    t = 0 # Total number of iterations\n",
    "    models = []\n",
    "    for cycle in range(cycles):\n",
    "        for epoch in range(epoch_n):\n",
    "            model.train()\n",
    "            print('=========================epoch %i=====================' % epoch)\n",
    "            epoch_loss = 0.0\n",
    "            running_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "            for i, data in enumerate(tqdm(train_loader)):\n",
    "                # update learning rate\n",
    "                t += 1\n",
    "                update_learning_rate(optimizer, lambda lr: shifted_cosine_function(t, 0.2))\n",
    "\n",
    "                inputs, _, study_type, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                loss.sum().backward()\n",
    "                optimizer.step()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.sum()\n",
    "                epoch_loss += loss.sum()\n",
    "\n",
    "            epoch_loss = epoch_loss / len(train_loader.dataset)\n",
    "            epoch_accuracy = epoch_corrects.double() / len(train_loader.dataset)\n",
    "            print('epoch loss: %.8f' % epoch_loss)\n",
    "            print('epoch accuracy: %.8f' % epoch_accuracy)\n",
    "\n",
    "            # else evaluate first then keep training\n",
    "            _, valid_loss, valid_acc, valid_kappa = validate_model(\n",
    "                [model],\n",
    "                validation_loader,\n",
    "                criterion,\n",
    "                optimizer,\n",
    "            )\n",
    "            print('epoch valid_loss: %8f' % valid_loss)\n",
    "            print('epoch valid_acc: %.8f' % valid_acc)\n",
    "            print('epoch valid_kappa: %.8f' % valid_kappa)\n",
    "        \n",
    "        print('cycle %i is over.' % cycle)\n",
    "        print('saving model..\\n')\n",
    "        models.append(model.state_dict())\n",
    "    return models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(models, validation_loader, criterion, optimizer):\n",
    "    \"\"\"\n",
    "    returns (df, acc, kappa)\n",
    "        df: Pandas dataframe containing study paths and their corresponding label\n",
    "        obtained by averaging the model scores on the study's images and treating any\n",
    "        score higher than 0.5 as abnormal.\n",
    "        \n",
    "        acc: model accuracy score on studies\n",
    "        kappa: model kappa score on studies\n",
    "    \"\"\"\n",
    "    for model in models:\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    all_study_names = []\n",
    "    all_outputs = []\n",
    "    \n",
    "    for i, data in enumerate(tqdm(validation_loader)):\n",
    "        inputs, study_names, study_types, labels = data\n",
    "        all_study_names += study_names\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            ensembled_outputs = []\n",
    "            for model in models:\n",
    "                outputs = model(inputs)\n",
    "                ensembled_outputs.append(outputs)\n",
    "            outputs = torch.stack(ensembled_outputs)\n",
    "            outputs = torch.mean(outputs, 0)\n",
    "            all_outputs += outputs.tolist()\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        total_loss += loss.sum()\n",
    "    \n",
    "    total_loss /= len(validation_loader.dataset)\n",
    "    results_df = pd.DataFrame({\n",
    "        'study': all_study_names,\n",
    "        'prediction': [np.argmax(o) for o in all_outputs]\n",
    "    })\n",
    "    \n",
    "    predicted_labeled_studies = results_df.groupby('study').agg({'prediction': lambda x: stats.mode(x, axis=None)[0][0]})\n",
    "    predicted_labeled_studies = predicted_labeled_studies.reset_index()\n",
    "\n",
    "    valid_labeled_studies = pd.read_csv(\n",
    "        'MURA-v1.1/valid_labeled_studies.csv',\n",
    "        header=None,\n",
    "        names= ['study', 'label']\n",
    "    )\n",
    "    \n",
    "   \n",
    "    joined_df = predicted_labeled_studies.join(valid_labeled_studies.set_index('study'), on='study')\n",
    "    \n",
    "    \n",
    "    accuracy = accuracy_score(joined_df.label, joined_df.prediction)\n",
    "    kappa = cohen_kappa_score(joined_df.label, joined_df.prediction)\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    confusion_m = confusion_matrix(joined_df.label, joined_df.prediction)\n",
    "    \n",
    "    return joined_df, total_loss.item(), accuracy, kappa, confusion_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4601 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================epoch 0=====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4601/4601 [03:31<00:00, 21.72it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 0.09168026\n",
      "epoch accuracy: 0.56732232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:10<00:00, 38.37it/s]\n",
      "  0%|          | 0/4601 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch valid_loss: 0.086643\n",
      "epoch valid_acc: 0.55129274\n",
      "epoch valid_kappa: 0.00000000\n",
      "=========================epoch 1=====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4601/4601 [02:20<00:00, 39.57it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 0.08751455\n",
      "epoch accuracy: 0.56797435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 47.64it/s]\n",
      "  0%|          | 0/4601 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch valid_loss: 0.087199\n",
      "epoch valid_acc: 0.55129274\n",
      "epoch valid_kappa: 0.00000000\n",
      "=========================epoch 2=====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4601/4601 [02:22<00:00, 32.36it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 0.08585342\n",
      "epoch accuracy: 0.57737448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 47.48it/s]\n",
      "  0%|          | 0/4601 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch valid_loss: 0.087403\n",
      "epoch valid_acc: 0.55129274\n",
      "epoch valid_kappa: 0.00000000\n",
      "=========================epoch 3=====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4601/4601 [02:21<00:00, 32.50it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 0.08535801\n",
      "epoch accuracy: 0.58506303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 47.93it/s]\n",
      "  0%|          | 0/4601 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch valid_loss: 0.086623\n",
      "epoch valid_acc: 0.55129274\n",
      "epoch valid_kappa: 0.00000000\n",
      "=========================epoch 4=====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4601/4601 [02:21<00:00, 32.48it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 0.08498706\n",
      "epoch accuracy: 0.58832319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 47.83it/s]\n",
      "  0%|          | 0/4601 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch valid_loss: 0.086676\n",
      "epoch valid_acc: 0.55129274\n",
      "epoch valid_kappa: 0.00000000\n",
      "=========================epoch 5=====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4601/4601 [02:20<00:00, 32.65it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 0.08456496\n",
      "epoch accuracy: 0.59506086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 47.53it/s]\n",
      "  0%|          | 0/4601 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch valid_loss: 0.087564\n",
      "epoch valid_acc: 0.55129274\n",
      "epoch valid_kappa: 0.00000000\n",
      "=========================epoch 6=====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 2612/4601 [01:20<00:59, 33.28it/s]"
     ]
    }
   ],
   "source": [
    "model = train_model_snapshot_ensembling(model, dataloaders_dict['train'], criterion, optimizer, epoch_n, M, dataloaders_dict['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    m = models.resnet18(pretrained=False)\n",
    "    num_ftrs = m.fc.in_features\n",
    "    m.fc = nn.Linear(num_ftrs, 2)\n",
    "    return m\n",
    "\n",
    "m1 = get_model().load_state_dict(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = [None, None, None, None, None]\n",
    "for i in range(5):\n",
    "    best_models[i] = get_model()\n",
    "    best_models[i].load_state_dict(model[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = [torch.load('resnet_model_crop')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 49.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch valid_loss: 0.069042\n",
      "epoch valid_acc: 0.74311927\n",
      "epoch valid_kappa: 0.45926618\n",
      "[[622  39]\n",
      " [269 269]]\n"
     ]
    }
   ],
   "source": [
    "_, valid_loss, valid_acc, valid_kappa, confusion_matrix = validate_model(\n",
    "        best_models,\n",
    "        dataloaders_dict['valid'],\n",
    "        criterion,\n",
    "        optimizer,\n",
    "    )\n",
    "\n",
    "print('epoch valid_loss: %8f' % valid_loss)\n",
    "print('epoch valid_acc: %.8f' % valid_acc)\n",
    "print('epoch valid_kappa: %.8f' % valid_kappa)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
